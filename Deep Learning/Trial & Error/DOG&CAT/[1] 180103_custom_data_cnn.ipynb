{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 : 개/고양이 binary classification\n",
    "## 모델 : ResNet-14 \n",
    "## 평가 결과 : 형편없음\n",
    "### - 심각한 overfitting 발생 <br> - V.A : 0.65 ~ 0.7 <br> - T.A : 0.4 ~ 0.5 ...\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red'>Convolutional Neural Network </font>\n",
    "- 작성자 : [Gauss Kim](https://github.com/gaussian37)<br>\n",
    "- 목적 : CNN의 다양한 model을 Custom Data에 맞게 사용할 수 있도록 지원<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from scipy.misc import imread, imresize, imshow\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  <font color='blue'>Hyper parameter</font>#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Image 사이즈 및 갯수 ###\n",
    "- resize할 image의 height와 width에 관한 hyper parameter\n",
    "- 이미지 갯수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_height = 64 # 이미지 height 크기\n",
    "img_width = 64 # 이미지 width 크기\n",
    "n_train = 4724 # train 이미지 갯수\n",
    "n_val = 1182# val 이미지 갯수\n",
    "n_test = 1477 # test 이미지 갯수\n",
    "n_class = 2 # class(카테고리) 갯수\n",
    "is_preproc = True # Input normalization 사용 여부"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - random seed ###\n",
    "랜덤 변수 시드 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "seed = 777\n",
    "tf.set_random_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Learning rate 초깃값 ###\n",
    "Back propagation 시 parameter update에 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Training Epoch ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_epochs = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - batch 사이즈 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blue'>TFRecord 읽어 오기</font> #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - tfrecord 파일명 및 경로 설정 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfrecord_train = 'train.tfrecord' # train 데이터 tfrecord\n",
    "tfrecord_val = 'val.tfrecord' # validation 데이터 tfrecord\n",
    "tfrecord_test = 'test.tfrecord' # test 데이터 tfrecord\n",
    "tfrecord_dir = 'tfrecords' # tfrecord 폴더"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - 이미지와 라벨 읽기 함수 생성 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 이미지와 라벨 읽어오기\n",
    "def read_and_decode(filename_queue, n_batch):    \n",
    "    reader = tf.TFRecordReader()\n",
    "    _, serialized_example = reader.read(filename_queue)\n",
    "    \n",
    "    features = tf.parse_single_example(\n",
    "        serialized_example,\n",
    "        features={            \n",
    "            'image': tf.FixedLenFeature([], tf.string),\n",
    "            'label': tf.FixedLenFeature([], tf.int64)\n",
    "        })    \n",
    "    # Convert from a scalar string tensor\n",
    "    image = tf.decode_raw(features['image'], tf.uint8)        \n",
    "    label = tf.cast(features['label'], tf.int32)\n",
    "    label_onehot = tf.one_hot(label, depth=n_class)\n",
    "    \n",
    "    image = tf.reshape(image, [img_height, img_width, 3])    \n",
    "    \n",
    "    images, labels = tf.train.batch([image, label_onehot],\n",
    "                                           batch_size=n_batch,\n",
    "                                           capacity=10000,\n",
    "                                           num_threads=4)    \n",
    "    return images, labels "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - image, label 파일 인풋 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# **** File input ***\n",
    "cwd = os.getcwd()\n",
    "train_path = os.path.join(cwd, tfrecord_dir, tfrecord_train)\n",
    "val_path = os.path.join(cwd, tfrecord_dir, tfrecord_val)\n",
    "test_path = os.path.join(cwd, tfrecord_dir, tfrecord_test)\n",
    "\n",
    "filename_queue_train = tf.train.string_input_producer([train_path], num_epochs=training_epochs)\n",
    "image_batch, label_batch = read_and_decode(filename_queue_train, batch_size)\n",
    "\n",
    "filename_queue_val = tf.train.string_input_producer([val_path], num_epochs=training_epochs)\n",
    "image_val, label_val = read_and_decode(filename_queue_val, batch_size)\n",
    "\n",
    "filename_queue_test = tf.train.string_input_producer([test_path], num_epochs=1)\n",
    "image_test, label_test = read_and_decode(filename_queue_test, n_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blue'>Function for Optimizing Neural Network</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 입력값 normalization : 이미지의 평균값 만큼 전체 이미지 값 감소\n",
    "def preproc(x):    \n",
    "    mean = tf.reduce_mean(x, axis=1, keep_dims=True)\n",
    "    return x - mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"background-color: #FFFF00\"> <font color='red'>ResNet</font></span> #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper parameter ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "number_of_resblk = 4\n",
    "number_of_layer = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_bn_activ(name, x, n_filters, kernel_size, strides, training, seed, padding='SAME'):\n",
    "    with tf.variable_scope(name):\n",
    "        net = tf.layers.conv2d(x, n_filters, kernel_size, strides=strides, padding=padding, use_bias=False, kernel_initializer=tf.contrib.layers.variance_scaling_initializer(seed=seed))\n",
    "        net = tf.layers.batch_normalization(net, training=training)\n",
    "        net = tf.nn.relu(net)\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def residual_block(name, x, n_filters, training, seed, downsample=False):    \n",
    "    if downsample:\n",
    "        strides = 2\n",
    "    else:\n",
    "        strides = 1\n",
    "    with tf.variable_scope(name):\n",
    "        net1 = conv_bn_activ(\"inner_conv1\",x, n_filters, [3, 3], strides, training, seed)\n",
    "        net2 = conv_bn_activ(\"inner_conv2\",x, n_filters, [3, 3], strides, training, seed)\n",
    "        \n",
    "        if downsample:\n",
    "            x = tf.layers.conv2d(x, n_filters, [1, 1], strides=2, padding='SAME',kernel_initializer=tf.contrib.layers.variance_scaling_initializer(seed=seed))\n",
    "        return tf.nn.relu(net2 + x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_resnet(X_img, resblk_n, layer_n, n_filters, training, seed):\n",
    "    net = X_img    \n",
    "    with tf.variable_scope(\"CONV0\"):\n",
    "        net = conv_bn_activ(\"pre_conv\", net, n_filters, [3, 3], 1, training, seed)\n",
    "        print(net)\n",
    "    \n",
    "    # 블락 생성\n",
    "    for i in range(resblk_n):\n",
    "        with tf.variable_scope(\"CONV\"+str(i+1)):\n",
    "            for j in range(layer_n):                \n",
    "                net = residual_block(\"resblk{}\".format(j), net, n_filters, training, seed, (j==0))\n",
    "                print(net)\n",
    "            n_filters *= 2\n",
    "            \n",
    "    with tf.variable_scope(\"GAP\"):        \n",
    "        pool_height, pool_width = net.shape[1:3]        \n",
    "        net = tf.layers.average_pooling2d(name=\"gap\", inputs=net, pool_size=[pool_height, pool_width], strides=1, padding='VALID')\n",
    "        print(net)\n",
    "        \n",
    "    with tf.variable_scope(\"FC\"):\n",
    "        logits = tf.layers.dense(net, n_class, name=\"logits\", kernel_initializer=tf.contrib.layers.variance_scaling_initializer(seed=seed))\n",
    "        logits = tf.reshape(logits, [-1, n_class]) # (?, 1, 1, n_class) → (?, n_class)\n",
    "        print(logits)\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blue'>Neural Network Design</font>#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Input Design ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, img_height, img_width, 3], name=\"X\")\n",
    "Y = tf.placeholder(tf.float32, [None, n_class], name = \"Y\")\n",
    "is_train = tf.placeholder(tf.bool, name=\"is_train\")\n",
    "\n",
    "#if is_preproc:\n",
    "#    X = preproc(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"CONV0/pre_conv/Relu:0\", shape=(?, 64, 64, 16), dtype=float32)\n",
      "Tensor(\"CONV1/resblk0/Relu:0\", shape=(?, 32, 32, 16), dtype=float32)\n",
      "Tensor(\"CONV1/resblk1/Relu:0\", shape=(?, 32, 32, 16), dtype=float32)\n",
      "Tensor(\"CONV1/resblk2/Relu:0\", shape=(?, 32, 32, 16), dtype=float32)\n",
      "Tensor(\"CONV2/resblk0/Relu:0\", shape=(?, 16, 16, 32), dtype=float32)\n",
      "Tensor(\"CONV2/resblk1/Relu:0\", shape=(?, 16, 16, 32), dtype=float32)\n",
      "Tensor(\"CONV2/resblk2/Relu:0\", shape=(?, 16, 16, 32), dtype=float32)\n",
      "Tensor(\"CONV3/resblk0/Relu:0\", shape=(?, 8, 8, 64), dtype=float32)\n",
      "Tensor(\"CONV3/resblk1/Relu:0\", shape=(?, 8, 8, 64), dtype=float32)\n",
      "Tensor(\"CONV3/resblk2/Relu:0\", shape=(?, 8, 8, 64), dtype=float32)\n",
      "Tensor(\"CONV4/resblk0/Relu:0\", shape=(?, 4, 4, 128), dtype=float32)\n",
      "Tensor(\"CONV4/resblk1/Relu:0\", shape=(?, 4, 4, 128), dtype=float32)\n",
      "Tensor(\"CONV4/resblk2/Relu:0\", shape=(?, 4, 4, 128), dtype=float32)\n",
      "Tensor(\"GAP/gap/AvgPool:0\", shape=(?, 1, 1, 128), dtype=float32)\n",
      "Tensor(\"FC/Reshape:0\", shape=(?, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "logits = build_resnet(X, number_of_resblk, number_of_layer, training=is_train, n_filters=16, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=Y), name=\"cost\")\n",
    "#n_batches_per_epoch = int(n_train / batch_size)\n",
    "\n",
    "update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "with tf.control_dependencies(update_ops):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost, name=\"optimizer\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 2) (?, 2)\n"
     ]
    }
   ],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print(logits.shape, Y.shape)\n",
    "\n",
    "# pred = tf.argmax(logits, axis=1, name=\"prediction\")\n",
    "# prob = tf.nn.softmax(logits, name=\"softmax\")\n",
    "# accuracy = tf.reduce_mean(tf.cast(tf.equal(pred, tf.argmax(Y, axis=1)), tf.float32), name=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_var = [X, Y, is_train, logits, accuracy]\n",
    "tf.add_to_collection('train_var', train_var[0])\n",
    "tf.add_to_collection('train_var', train_var[1])\n",
    "tf.add_to_collection('train_var', train_var[2])\n",
    "tf.add_to_collection('train_var', train_var[3])\n",
    "tf.add_to_collection('train_var', train_var[4])\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialize\n",
    "init_op = tf.group(tf.global_variables_initializer(),tf.local_variables_initializer())\n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=tf.GPUOptions(allow_growth =True)))\n",
    "sess.run(tf.global_variables_initializer())\n",
    "sess.run(init_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "coord = tf.train.Coordinator()\n",
    "threads = tf.train.start_queue_runners(coord=coord, sess=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning started. It takes sometime.\n",
      "Epoch: 0001 cost = 1.000645252 train accuracy =  0.64711 validation accuracy =  0.55035\n",
      "Epoch: 0002 cost = 0.636091569 train accuracy =  0.66986 validation accuracy =  0.64149\n",
      "Epoch: 0003 cost = 0.612781999 train accuracy =  0.67708 validation accuracy =  0.46528\n",
      "Epoch: 0004 cost = 0.576954134 train accuracy =  0.70174 validation accuracy =  0.68056\n",
      "Epoch: 0005 cost = 0.545384338 train accuracy =  0.72725 validation accuracy =  0.65191\n",
      "Epoch: 0006 cost = 0.519557853 train accuracy =  0.74660 validation accuracy =  0.66406\n",
      "Epoch: 0007 cost = 0.505570489 train accuracy =  0.75446 validation accuracy =  0.69358\n",
      "Epoch: 0008 cost = 0.472953455 train accuracy =  0.77105 validation accuracy =  0.70920\n",
      "Epoch: 0009 cost = 0.450774471 train accuracy =  0.78678 validation accuracy =  0.68750\n",
      "Epoch: 0010 cost = 0.427860073 train accuracy =  0.80548 validation accuracy =  0.69097\n",
      "Epoch: 0011 cost = 0.415239851 train accuracy =  0.80123 validation accuracy =  0.70747\n",
      "Epoch: 0012 cost = 0.385615371 train accuracy =  0.82717 validation accuracy =  0.70660\n",
      "Epoch: 0013 cost = 0.355834513 train accuracy =  0.84077 validation accuracy =  0.69358\n",
      "Epoch: 0014 cost = 0.339212680 train accuracy =  0.85480 validation accuracy =  0.62326\n",
      "Epoch: 0015 cost = 0.325573766 train accuracy =  0.85714 validation accuracy =  0.61632\n",
      "Epoch: 0016 cost = 0.270600677 train accuracy =  0.87968 validation accuracy =  0.64670\n",
      "Epoch: 0017 cost = 0.264079725 train accuracy =  0.88435 validation accuracy =  0.67014\n",
      "Epoch: 0018 cost = 0.239683840 train accuracy =  0.90051 validation accuracy =  0.56510\n",
      "Epoch: 0019 cost = 0.212195403 train accuracy =  0.91008 validation accuracy =  0.67969\n",
      "Epoch: 0020 cost = 0.169117984 train accuracy =  0.93176 validation accuracy =  0.67795\n",
      "Epoch: 0021 cost = 0.190412725 train accuracy =  0.92368 validation accuracy =  0.68229\n",
      "Epoch: 0022 cost = 0.180611187 train accuracy =  0.92645 validation accuracy =  0.67795\n",
      "Epoch: 0023 cost = 0.148649285 train accuracy =  0.94303 validation accuracy =  0.70226\n",
      "Epoch: 0024 cost = 0.126543700 train accuracy =  0.94983 validation accuracy =  0.67969\n",
      "Epoch: 0025 cost = 0.124810146 train accuracy =  0.95536 validation accuracy =  0.64062\n",
      "Epoch: 0026 cost = 0.118701498 train accuracy =  0.95174 validation accuracy =  0.70573\n",
      "Epoch: 0027 cost = 0.105677439 train accuracy =  0.96216 validation accuracy =  0.68490\n",
      "Epoch: 0028 cost = 0.096084884 train accuracy =  0.96216 validation accuracy =  0.69878\n",
      "Epoch: 0029 cost = 0.078682594 train accuracy =  0.97045 validation accuracy =  0.68576\n",
      "Epoch: 0030 cost = 0.098946464 train accuracy =  0.96407 validation accuracy =  0.70920\n",
      "Epoch: 0031 cost = 0.067099079 train accuracy =  0.97577 validation accuracy =  0.70052\n",
      "Epoch: 0032 cost = 0.075892058 train accuracy =  0.96939 validation accuracy =  0.69184\n",
      "Epoch: 0033 cost = 0.075510163 train accuracy =  0.97151 validation accuracy =  0.70052\n",
      "Epoch: 0034 cost = 0.063072932 train accuracy =  0.97577 validation accuracy =  0.70486\n",
      "Epoch: 0035 cost = 0.072603677 train accuracy =  0.97406 validation accuracy =  0.68403\n",
      "Epoch: 0036 cost = 0.084270601 train accuracy =  0.96981 validation accuracy =  0.71441\n",
      "Epoch: 0037 cost = 0.062011568 train accuracy =  0.97938 validation accuracy =  0.68056\n",
      "Epoch: 0038 cost = 0.042968805 train accuracy =  0.98406 validation accuracy =  0.71788\n",
      "Epoch: 0039 cost = 0.053576988 train accuracy =  0.97895 validation accuracy =  0.71267\n",
      "Epoch: 0040 cost = 0.048587162 train accuracy =  0.98363 validation accuracy =  0.72222\n",
      "Epoch: 0041 cost = 0.065897688 train accuracy =  0.97640 validation accuracy =  0.70486\n",
      "Epoch: 0042 cost = 0.062703338 train accuracy =  0.97555 validation accuracy =  0.70486\n",
      "Epoch: 0043 cost = 0.086325632 train accuracy =  0.96790 validation accuracy =  0.70833\n",
      "Epoch: 0044 cost = 0.045595575 train accuracy =  0.98321 validation accuracy =  0.71181\n",
      "Epoch: 0045 cost = 0.062925056 train accuracy =  0.97577 validation accuracy =  0.69358\n",
      "Epoch: 0046 cost = 0.044669624 train accuracy =  0.98533 validation accuracy =  0.71007\n",
      "Epoch: 0047 cost = 0.039300877 train accuracy =  0.98512 validation accuracy =  0.71181\n",
      "Epoch: 0048 cost = 0.041768534 train accuracy =  0.98363 validation accuracy =  0.70747\n",
      "Epoch: 0049 cost = 0.089153538 train accuracy =  0.96960 validation accuracy =  0.70052\n",
      "Epoch: 0050 cost = 0.038909127 train accuracy =  0.98639 validation accuracy =  0.69184\n",
      "Epoch: 0051 cost = 0.042879101 train accuracy =  0.98682 validation accuracy =  0.68663\n",
      "Epoch: 0052 cost = 0.043795840 train accuracy =  0.98299 validation accuracy =  0.69792\n",
      "Epoch: 0053 cost = 0.071939629 train accuracy =  0.97449 validation accuracy =  0.69878\n",
      "Epoch: 0054 cost = 0.065438208 train accuracy =  0.97619 validation accuracy =  0.65885\n",
      "Epoch: 0055 cost = 0.057518707 train accuracy =  0.97874 validation accuracy =  0.69184\n",
      "Epoch: 0056 cost = 0.046066524 train accuracy =  0.98108 validation accuracy =  0.70052\n",
      "Epoch: 0057 cost = 0.026286045 train accuracy =  0.98937 validation accuracy =  0.69878\n",
      "Epoch: 0058 cost = 0.034396782 train accuracy =  0.98703 validation accuracy =  0.70399\n",
      "Epoch: 0059 cost = 0.029810787 train accuracy =  0.99022 validation accuracy =  0.67448\n",
      "Epoch: 0060 cost = 0.035536195 train accuracy =  0.98788 validation accuracy =  0.69097\n",
      "Epoch: 0061 cost = 0.048801051 train accuracy =  0.98214 validation accuracy =  0.67101\n",
      "Epoch: 0062 cost = 0.048853831 train accuracy =  0.98321 validation accuracy =  0.69618\n",
      "Epoch: 0063 cost = 0.063470203 train accuracy =  0.98129 validation accuracy =  0.67274\n",
      "Epoch: 0064 cost = 0.026380303 train accuracy =  0.98916 validation accuracy =  0.67535\n",
      "Epoch: 0065 cost = 0.044804880 train accuracy =  0.98427 validation accuracy =  0.70486\n",
      "Epoch: 0066 cost = 0.029068905 train accuracy =  0.98810 validation accuracy =  0.67101\n",
      "Epoch: 0067 cost = 0.038104959 train accuracy =  0.98639 validation accuracy =  0.65799\n",
      "Epoch: 0068 cost = 0.049925406 train accuracy =  0.98172 validation accuracy =  0.68924\n",
      "Epoch: 0069 cost = 0.058460771 train accuracy =  0.97959 validation accuracy =  0.66753\n",
      "Epoch: 0070 cost = 0.062920026 train accuracy =  0.97810 validation accuracy =  0.69184\n",
      "Epoch: 0071 cost = 0.030192788 train accuracy =  0.98937 validation accuracy =  0.69358\n",
      "Epoch: 0072 cost = 0.019016377 train accuracy =  0.99362 validation accuracy =  0.67361\n",
      "Epoch: 0073 cost = 0.016577879 train accuracy =  0.99384 validation accuracy =  0.69618\n",
      "Epoch: 0074 cost = 0.015670584 train accuracy =  0.99362 validation accuracy =  0.70226\n",
      "Epoch: 0075 cost = 0.014741613 train accuracy =  0.99532 validation accuracy =  0.67795\n",
      "Epoch: 0076 cost = 0.025102215 train accuracy =  0.99086 validation accuracy =  0.71267\n",
      "Epoch: 0077 cost = 0.052036002 train accuracy =  0.98321 validation accuracy =  0.64149\n",
      "Epoch: 0078 cost = 0.067053191 train accuracy =  0.97704 validation accuracy =  0.67014\n",
      "Epoch: 0079 cost = 0.056864465 train accuracy =  0.98087 validation accuracy =  0.69878\n",
      "Epoch: 0080 cost = 0.053832373 train accuracy =  0.98214 validation accuracy =  0.70139\n",
      "Epoch: 0081 cost = 0.024661534 train accuracy =  0.99086 validation accuracy =  0.65451\n",
      "Epoch: 0082 cost = 0.022814212 train accuracy =  0.99213 validation accuracy =  0.68576\n",
      "Epoch: 0083 cost = 0.017057336 train accuracy =  0.99256 validation accuracy =  0.70052\n",
      "Epoch: 0084 cost = 0.043925061 train accuracy =  0.98661 validation accuracy =  0.68924\n",
      "Epoch: 0085 cost = 0.042976047 train accuracy =  0.98469 validation accuracy =  0.68229\n",
      "Epoch: 0086 cost = 0.069125120 train accuracy =  0.97917 validation accuracy =  0.68576\n",
      "Epoch: 0087 cost = 0.062686648 train accuracy =  0.98065 validation accuracy =  0.64236\n",
      "Epoch: 0088 cost = 0.037741868 train accuracy =  0.98533 validation accuracy =  0.69444\n",
      "Epoch: 0089 cost = 0.014962751 train accuracy =  0.99575 validation accuracy =  0.69097\n",
      "Epoch: 0090 cost = 0.013570825 train accuracy =  0.99469 validation accuracy =  0.71181\n",
      "Epoch: 0091 cost = 0.020902510 train accuracy =  0.99235 validation accuracy =  0.62587\n",
      "Epoch: 0092 cost = 0.042921458 train accuracy =  0.98533 validation accuracy =  0.69531\n",
      "Epoch: 0093 cost = 0.075021165 train accuracy =  0.97598 validation accuracy =  0.69531\n",
      "Epoch: 0094 cost = 0.030700471 train accuracy =  0.98980 validation accuracy =  0.69271\n",
      "Epoch: 0095 cost = 0.014159664 train accuracy =  0.99426 validation accuracy =  0.70573\n",
      "Epoch: 0096 cost = 0.034432896 train accuracy =  0.98852 validation accuracy =  0.69618\n",
      "Epoch: 0097 cost = 0.023801899 train accuracy =  0.99150 validation accuracy =  0.68316\n",
      "Epoch: 0098 cost = 0.040011963 train accuracy =  0.98746 validation accuracy =  0.65017\n",
      "Epoch: 0099 cost = 0.038980047 train accuracy =  0.98639 validation accuracy =  0.68056\n",
      "Epoch: 0100 cost = 0.048181735 train accuracy =  0.98363 validation accuracy =  0.68924\n",
      "Learning Finished!\n"
     ]
    }
   ],
   "source": [
    "# train my model\n",
    "print('Learning started. It takes sometime.')\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0.\n",
    "    avg_train_acc = 0.\n",
    "    avg_val_acc = 0.\n",
    "    total_batch = int(n_train / batch_size)\n",
    "    total_batch_val = int(n_val / batch_size)\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        try:\n",
    "            batch_xs, batch_ys = sess.run([image_batch, label_batch])\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            pass\n",
    "        batch_xs = batch_xs/255.        \n",
    "        feed_dict = {X: batch_xs, Y: batch_ys, is_train: True}\n",
    "        #feed_dict = {X: batch_xs, Y: batch_ys, keep_prob: 0.7}\n",
    "        acc, c, _ = sess.run([accuracy, cost, optimizer], feed_dict=feed_dict)\n",
    "        avg_cost += c / total_batch\n",
    "        avg_train_acc += acc / total_batch\n",
    "    \n",
    "    for i in range(total_batch_val):\n",
    "        batch_xs, batch_ys = sess.run([image_val, label_val])\n",
    "        batch_xs = batch_xs/255.\n",
    "        feed_dict = {X: batch_xs, Y: batch_ys, is_train: False}\n",
    "        acc = sess.run(accuracy, feed_dict=feed_dict)\n",
    "        avg_val_acc += acc / total_batch_val\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost), 'train accuracy = ', \n",
    "         '{:.5f}'.format(avg_train_acc), 'validation accuracy = ', '{:.5f}'.format(avg_val_acc))\n",
    "\n",
    "\n",
    "print('Learning Finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.463101\n"
     ]
    }
   ],
   "source": [
    "test_xs, test_ys = sess.run([image_test, label_test])\n",
    "print('Test Accuracy:', sess.run(accuracy, feed_dict={X: test_xs, Y: test_ys, is_train:False}))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
