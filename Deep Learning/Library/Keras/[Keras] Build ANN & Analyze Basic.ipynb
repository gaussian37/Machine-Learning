{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-04T19:49:34.818174Z",
     "start_time": "2018-02-04T19:49:34.813161Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np # numpy\n",
    "from random import randint # data set을 만들기 위한 random library\n",
    "from sklearn.preprocessing import MinMaxScaler # data normaliza를 위한 scale 라이브러리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 예제\n",
    "- 13 ~ 65세를 위한 어떤 약을 만들기 위해 임상실험 진행\n",
    "- 2000명의 표본으로 반은 65세 이하를 대상으로 나머지 반은 65세 이상으로 진행\n",
    "- 95%의 확률로 65세 이상은 부작용 발생\n",
    "- 95%의 확률로 65세 미만은 부작용 미발생"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-04T19:49:37.068742Z",
     "start_time": "2018-02-04T19:49:37.049712Z"
    }
   },
   "outputs": [],
   "source": [
    "# X_data : train 데이터, Y_data : label\n",
    "# 13 ~ 64세는 95%는 부작용 미발생, 5% 발생\n",
    "# 65세 이상(100세 이하)는 95%는 부작용 발생, 5%는 미발생\n",
    "# 2000개의 데이터 = 950(13 ~64 : 0) + 50(13 ~ 64 : 1) + 950(65 ~ 100 : 1) + 50(65 ~ 100 : 0)\n",
    "\n",
    "# Train data 생성, 나이는 13 ~ 64세로 랜덤하게 만들며 1000개의 샘플을 만듭니다.\n",
    "X_data = np.random.randint(low = 13, high = 64, size = 1000) \n",
    "# Test data 생성, 나이는 13 ~ 64세이고 95%는 무작용 미발생, 5%는 발생하도록 만듭니다.\n",
    "Y_data = np.zeros(950) # 13 ~ 64세 95%는 부작용 미발생\n",
    "Y_data = np.append(Y_data, np.ones(50)) # 13 ~ 64 95%는 부작용 발생\n",
    "\n",
    "# Training data 생성, 나이는 65~100세로 랜덤하게 만들며 1000개의 샘플을 만듭니다.\n",
    "X_data = np.append(X_data, np.random.randint(low = 65, high = 100, size = 1000))\n",
    "# test data 생성, 나이는 65 ~ 100세이고, 95%는 부작용 발생, 5%는 부작용 미발생하도록 만듭니다.\n",
    "Y_data = np.append(Y_data, np.ones(950)) # 65 ~ 100세 95%는 부작용 발생\n",
    "Y_data = np.append(Y_data, np.zeros(50)) # 65 ~ 100세 5%는 부작용 미발생"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-04T19:49:38.194630Z",
     "start_time": "2018-02-04T19:49:38.187128Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\infoe\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int32 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "C:\\Users\\infoe\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:324: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "C:\\Users\\infoe\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:359: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Input data scale : 너무 큰 input 값은 weight가 수렴하는 데 오래 걸려\n",
    "# 학습하는 데 시간이 오래 걸리므로 data scale을 통하여 값을 줄여주어 빠르게 학습하도록 합니다.\n",
    "\n",
    "# [0, 1] 사이의 값으로 스케일 변화를 위한 변수 생성\n",
    "scalar = MinMaxScaler(feature_range= (0, 1)) \n",
    "# (None, 1) shape으로 [0,1] 범위로 스케일 변경\n",
    "scaled_X_data = scalar.fit_transform(X_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-04T19:49:38.886179Z",
     "start_time": "2018-02-04T19:49:38.875181Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_data :  [60 15 29 ... 71 93 83]\n",
      "X_data.shape :  (2000,)\n",
      "scaled_X_data :  [0.54651163 0.02325581 0.18604651 ... 0.6744186  0.93023256 0.81395349]\n",
      "(2000,)\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "(2000,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_data : \", X_data) # Train data\n",
    "print(\"X_data.shape : \", X_data.shape) # Train data shape\n",
    "print(\"scaled_X_data : \", scaled_X_data) # scaled train data\n",
    "print(scaled_X_data.shape) # scaled train data shape\n",
    "print(Y_data) # Label data\n",
    "print(Y_data.shape) # label data shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-04T19:49:40.082513Z",
     "start_time": "2018-02-04T19:49:40.073515Z"
    }
   },
   "outputs": [],
   "source": [
    "import keras \n",
    "from keras import backend as K \n",
    "from keras.models import Sequential # Sequential : model 선언\n",
    "from keras.layers import Activation # Activation 사용\n",
    "from keras.layers.core import Dense # Dense layer 사용\n",
    "from keras.optimizers import Adam # Adam optimizer 사용\n",
    "from keras.metrics import categorical_crossentropy # cross entropy 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Sequential을 선언한 후 layer를 쌓습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-04T19:49:41.694037Z",
     "start_time": "2018-02-04T19:49:41.625331Z"
    }
   },
   "outputs": [],
   "source": [
    "# Sequential()을 이용하여 model을 선언합니다.\n",
    "model = Sequential()\n",
    "# model의 전체 틀은 model.summary()를 이용하여 확인하면 보기 편합니다.\n",
    "\n",
    "# Dense layer를 추가합니다. 1-dim vector → (None, 16)\n",
    "# activation으로 ReLU를 사용합니다.\n",
    "model.add(Dense(16, input_shape=(1,), activation = 'relu'))\n",
    "# Dense layer를 추가합니다. → (None, 32)\n",
    "# activation으로 ReLU를 사용합니다.\n",
    "model.add(Dense(32, activation='relu'))\n",
    "# Dense layer를 추가합니다. → (None, 2)\n",
    "# 출력층이므로 activation으로 softmax를 사용합니다.\n",
    "model.add(Dense(2, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 쌓은 layer의 정보를 얻습니다. shape 및 parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-04T19:49:42.430364Z",
     "start_time": "2018-02-04T19:49:42.425879Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 16)                32        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 642\n",
      "Trainable params: 642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 각 layer의 output shape과 Parameter의 수를 요약해서 볼 수 있습니다.\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-04T19:54:01.079874Z",
     "start_time": "2018-02-04T19:54:01.016615Z"
    }
   },
   "outputs": [],
   "source": [
    "# model.compile을 이용하여 optimizer와 loss를 선언합니다. \n",
    "# optimizer(학습 방법) : Adam \n",
    "# loss function(loss 계산 방법) : sparse_categorical_cross_entropy (one-hot 아닐 때는 sparse 써야한다.)\n",
    "# metrics(performance 판단 기준) : accuracy\n",
    "model.compile(optimizer = Adam(lr = 0.001), \n",
    "              loss = 'sparse_categorical_crossentropy', \n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-04T19:54:11.024916Z",
     "start_time": "2018-02-04T19:54:02.542051Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2000/2000 [==============================] - 1s 329us/step - loss: 0.2059 - acc: 0.9500\n",
      "Epoch 2/20\n",
      "2000/2000 [==============================] - 0s 225us/step - loss: 0.2065 - acc: 0.9485\n",
      "Epoch 3/20\n",
      "2000/2000 [==============================] - 0s 191us/step - loss: 0.2069 - acc: 0.9480\n",
      "Epoch 4/20\n",
      "2000/2000 [==============================] - 0s 206us/step - loss: 0.2055 - acc: 0.9480\n",
      "Epoch 5/20\n",
      "2000/2000 [==============================] - 0s 197us/step - loss: 0.2060 - acc: 0.9500\n",
      "Epoch 6/20\n",
      "2000/2000 [==============================] - 0s 203us/step - loss: 0.2047 - acc: 0.9500\n",
      "Epoch 7/20\n",
      "2000/2000 [==============================] - 0s 199us/step - loss: 0.2051 - acc: 0.9500\n",
      "Epoch 8/20\n",
      "2000/2000 [==============================] - 0s 196us/step - loss: 0.2062 - acc: 0.9490\n",
      "Epoch 9/20\n",
      "2000/2000 [==============================] - 0s 201us/step - loss: 0.2037 - acc: 0.9500\n",
      "Epoch 10/20\n",
      "2000/2000 [==============================] - 0s 196us/step - loss: 0.2051 - acc: 0.9500\n",
      "Epoch 11/20\n",
      "2000/2000 [==============================] - 0s 202us/step - loss: 0.2044 - acc: 0.9500\n",
      "Epoch 12/20\n",
      "2000/2000 [==============================] - 0s 196us/step - loss: 0.2044 - acc: 0.9490\n",
      "Epoch 13/20\n",
      "2000/2000 [==============================] - 0s 203us/step - loss: 0.2044 - acc: 0.9500\n",
      "Epoch 14/20\n",
      "2000/2000 [==============================] - 0s 194us/step - loss: 0.2045 - acc: 0.9490\n",
      "Epoch 15/20\n",
      "2000/2000 [==============================] - 0s 187us/step - loss: 0.2039 - acc: 0.9500\n",
      "Epoch 16/20\n",
      "2000/2000 [==============================] - 0s 185us/step - loss: 0.2052 - acc: 0.9490\n",
      "Epoch 17/20\n",
      "2000/2000 [==============================] - 0s 200us/step - loss: 0.2041 - acc: 0.9500\n",
      "Epoch 18/20\n",
      "2000/2000 [==============================] - 0s 214us/step - loss: 0.2039 - acc: 0.9495\n",
      "Epoch 19/20\n",
      "2000/2000 [==============================] - 0s 202us/step - loss: 0.2037 - acc: 0.9500\n",
      "Epoch 20/20\n",
      "2000/2000 [==============================] - 0s 196us/step - loss: 0.2040 - acc: 0.9500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2e6e2093438>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.fit을 통하여 학습을 합니다.\n",
    "# input data : scaled_X_data \n",
    "# output data : Y_data\n",
    "# batch size : 10\n",
    "# epochs : 20\n",
    "# shuffle (epoch 마다 batch 순서가 shuffle 되는 지 유무) : True (default : True)\n",
    "\n",
    "model.fit(scaled_X_data, Y_data, batch_size=16, epochs=20, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 277.181818,
   "position": {
    "height": "40px",
    "left": "1375.45px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
