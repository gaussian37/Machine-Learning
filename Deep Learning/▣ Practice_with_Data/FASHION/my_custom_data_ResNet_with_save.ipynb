{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Fashion data with ResNet ##\n",
    "\n",
    "** Applied Hyperparameter **\n",
    "\n",
    "- Learing rate = 0.01\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;: 현재 validation accuracy가 이전 accuracy 보다 감소 하였을 때(overfitting 가정) learing rate 0.5 배\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ☞ **Learning_rate_decay** 함수 참조\n",
    "\n",
    "- batch size = 64\n",
    "\n",
    "- L2 regularization ([사용 방법 참조](http://gaussian37.me/221143520556))\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; : CNN 커널 및 FC의 weight에 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "#%env CUDA_VISIBLE_DEVICES=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from scipy.misc import imread, imresize\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Modify !!! #############\n",
    "save_filename = 'jinsolkim.ckpt'\n",
    "############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_width = 28\n",
    "img_height = 28\n",
    "\n",
    "tfrecord_train = 'fashion_train.tfrecord'\n",
    "tfrecord_val = 'fashion_val.tfrecord'\n",
    "tfrecord_dir = 'tfrecords'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hyper parameters\n",
    "seed = 777\n",
    "learning_rate = 0.01 # 변경\n",
    "training_epochs = 50\n",
    "batch_size = 64 # batch size 2^N\n",
    "n_train = 50000\n",
    "n_val = 10000\n",
    "n_class = 10\n",
    "lambda_reg = 0.01 # 추가\n",
    "tf.set_random_seed(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_and_decode(filename_queue, n_batch):\n",
    "    \n",
    "    reader = tf.TFRecordReader()\n",
    "    _, serialized_example = reader.read(filename_queue)\n",
    "    \n",
    "    features = tf.parse_single_example(\n",
    "        serialized_example,\n",
    "        features={            \n",
    "            'image': tf.FixedLenFeature([], tf.string),\n",
    "            'label': tf.FixedLenFeature([], tf.int64)\n",
    "        })\n",
    "    \n",
    "    # Convert from a scalar string tensor\n",
    "    image = tf.decode_raw(features['image'], tf.uint8)        \n",
    "    label = tf.cast(features['label'], tf.int32)\n",
    "    label_onehot = tf.one_hot(label, depth=n_class)\n",
    "    \n",
    "    image = tf.reshape(image, [img_height, img_width, 1])    \n",
    "    \n",
    "    images, labels = tf.train.batch([image, label_onehot],\n",
    "                                           batch_size=n_batch,\n",
    "                                           capacity=10000,\n",
    "                                           num_threads=4)\n",
    "    \n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preproc(x):\n",
    "    # x = x*2 - 1.0\n",
    "    # per-example mean subtraction (http://ufldl.stanford.edu/wiki/index.php/Data_Preprocessing)\n",
    "    mean = tf.reduce_mean(x, axis=1, keep_dims=True)\n",
    "    return x - mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_bn_activ(name, x, n_filters, kernel_size, strides, training, seed, padding='SAME'):\n",
    "    with tf.variable_scope(name):\n",
    "        net = tf.layers.conv2d(x, n_filters, kernel_size, strides=strides, padding=padding, use_bias=False,\n",
    "                              kernel_initializer=tf.contrib.layers.variance_scaling_initializer(seed=seed))\n",
    "        net = tf.layers.batch_normalization(net, training=training)\n",
    "        net = tf.nn.relu(net)\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def residual_block(name, x, n_filters, training, seed, downsample=False):    \n",
    "    if downsample:\n",
    "        strides = 2\n",
    "    else:\n",
    "        strides = 1\n",
    "    with tf.variable_scope(name):\n",
    "        regularizer = tf.contrib.layers.l2_regularizer(scale=lambda_reg)\n",
    "        with tf.variable_scope(\"inner_conv1\"):            \n",
    "            net1 = tf.layers.conv2d(x, n_filters, [3, 3], strides=strides, padding='SAME', use_bias=False, kernel_regularizer=regularizer)\n",
    "            net1 = tf.layers.batch_normalization(net1, training=training)\n",
    "            net1 = tf.nn.relu(net1)\n",
    "        with tf.variable_scope(\"inner_conv2\"):\n",
    "            net2 = tf.layers.conv2d(net1, n_filters, [3, 3], strides=1, padding='SAME', use_bias=False, kernel_regularizer=regularizer)\n",
    "            net2 = tf.layers.batch_normalization(net2, training=training)\n",
    "        if downsample:\n",
    "            x = tf.layers.conv2d(x, n_filters, [1, 1], strides=2, padding='SAME', kernel_regularizer=regularizer)\n",
    "        return tf.nn.relu(net2 + x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_resnet(X_img, layer_n, training, seed):\n",
    "    regularizer = tf.contrib.layers.l2_regularizer(scale=lambda_reg)\n",
    "    net = X_img\n",
    "    with tf.variable_scope(\"conv0\"):\n",
    "        net = conv_bn_activ(name=\"pre_conv\", x=net, n_filters=16, kernel_size=[3,3], strides=1, \n",
    "                            training=is_train, seed=seed)\n",
    "    with tf.variable_scope(\"conv1\"):\n",
    "        for i in range(layer_n):\n",
    "            net = residual_block(name=\"resblk{}\".format(i), x=net, n_filters=16, training=training, \n",
    "                                 seed=seed)\n",
    "            print(net)\n",
    "    with tf.variable_scope(\"conv2\"):\n",
    "        for i in range(layer_n):\n",
    "            net = residual_block(name=\"resblk{}\".format(i), x=net, n_filters=32, training=training, \n",
    "                                 seed=seed, downsample=(i==0))\n",
    "            print(net)\n",
    "    with tf.variable_scope(\"conv3\"):\n",
    "        for i in range(layer_n):\n",
    "            net = residual_block(name=\"resblk{}\".format(i), x=net, n_filters=64, training=training, \n",
    "                                 seed=seed, downsample=(i==0))\n",
    "            print(net)\n",
    "    with tf.variable_scope(\"conv4\"):\n",
    "        for i in range(layer_n):\n",
    "            net = residual_block(name=\"resblk{}\".format(i), x=net, n_filters=64, training=training, \n",
    "                                 seed=seed, downsample=(i==0))\n",
    "            print(net)\n",
    "    \n",
    "    with tf.variable_scope(\"fc\"):\n",
    "        net = tf.layers.average_pooling2d(name=\"gap\", inputs=net, pool_size=[7, 7], \n",
    "                                          strides=7, padding='SAME')\n",
    "        print(net)\n",
    "        net = tf.reshape(net, [-1, 64])\n",
    "        print(net)\n",
    "        logits = tf.layers.dense(net, 10, name=\"logits\", kernel_regularizer=regularizer)\n",
    "        print(logits)\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, img_height, img_width, 1])\n",
    "Y = tf.placeholder(tf.float32, [None, n_class])\n",
    "is_train = tf.placeholder(tf.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X_pre = preproc(X)\n",
    "# X_img = tf.reshape(X, [-1, 28, 28, 1], name=\"X_img\")\n",
    "# X_img = tf.reshape(X_pre, [-1, 28, 28, 1], name=\"X_img\")\n",
    "#print(X)\n",
    "#print(X_pre)\n",
    "#print(X_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"conv1/resblk0/Relu:0\", shape=(?, 28, 28, 16), dtype=float32)\n",
      "Tensor(\"conv1/resblk1/Relu:0\", shape=(?, 28, 28, 16), dtype=float32)\n",
      "Tensor(\"conv1/resblk2/Relu:0\", shape=(?, 28, 28, 16), dtype=float32)\n",
      "Tensor(\"conv2/resblk0/Relu:0\", shape=(?, 14, 14, 32), dtype=float32)\n",
      "Tensor(\"conv2/resblk1/Relu:0\", shape=(?, 14, 14, 32), dtype=float32)\n",
      "Tensor(\"conv2/resblk2/Relu:0\", shape=(?, 14, 14, 32), dtype=float32)\n",
      "Tensor(\"conv3/resblk0/Relu:0\", shape=(?, 7, 7, 64), dtype=float32)\n",
      "Tensor(\"conv3/resblk1/Relu:0\", shape=(?, 7, 7, 64), dtype=float32)\n",
      "Tensor(\"conv3/resblk2/Relu:0\", shape=(?, 7, 7, 64), dtype=float32)\n",
      "Tensor(\"conv4/resblk0/Relu:0\", shape=(?, 4, 4, 64), dtype=float32)\n",
      "Tensor(\"conv4/resblk1/Relu:0\", shape=(?, 4, 4, 64), dtype=float32)\n",
      "Tensor(\"conv4/resblk2/Relu:0\", shape=(?, 4, 4, 64), dtype=float32)\n",
      "Tensor(\"fc/gap/AvgPool:0\", shape=(?, 1, 1, 64), dtype=float32)\n",
      "Tensor(\"fc/Reshape:0\", shape=(?, 64), dtype=float32)\n",
      "Tensor(\"fc/logits/BiasAdd:0\", shape=(?, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "logits = build_resnet(X, layer_n=3, training=is_train, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=Y), name=\"loss\")\n",
    "#n_batches_per_epoch = int(mnist.train.num_examples / batch_size)\n",
    "#decay_steps = int(n_batches_per_epoch * num_epochs_per_decay)\n",
    "#global_step = tf.Variable(0, trainable=False)\n",
    "#learningRate = tf.train.exponential_decay(learning_rate=learning_rate,\n",
    "#                                          global_step= global_step,\n",
    "#                                          decay_steps=decay_steps,\n",
    "#                                          decay_rate= 0.15,\n",
    "#                                          staircase=True)\n",
    "\n",
    "update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "with tf.control_dependencies(update_ops):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss, name=\"optimizer\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "train_path = os.path.join(cwd, '..', tfrecord_dir, tfrecord_train)\n",
    "val_path = os.path.join(cwd, '..', tfrecord_dir, tfrecord_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename_queue = tf.train.string_input_producer([train_path], num_epochs=training_epochs)\n",
    "image_batch, label_batch = read_and_decode(filename_queue, batch_size)\n",
    "filename_queue_val = tf.train.string_input_producer([val_path], num_epochs=training_epochs)\n",
    "image_val, label_val = read_and_decode(filename_queue_val, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_var = [X, Y, is_train, logits, accuracy]\n",
    "tf.add_to_collection('train_var', train_var[0])\n",
    "tf.add_to_collection('train_var', train_var[1])\n",
    "tf.add_to_collection('train_var', train_var[2])\n",
    "tf.add_to_collection('train_var', train_var[3])\n",
    "tf.add_to_collection('train_var', train_var[4])\n",
    "saver = tf.train.Saver()\n",
    "##saver.export_meta_graph(os.path.join(cur_dir, 'checkpoints', 'mnist_ckpt.meta'), collection_list=['train_var'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init_op = tf.group(tf.global_variables_initializer(),\n",
    "                      tf.local_variables_initializer())\n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=tf.GPUOptions(allow_growth =True)))\n",
    "sess.run(init_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def learning_rate_decay(learing_rate, weight, pre_val_acc, now_val_acc):\n",
    "    if pre_val_acc > now_val_acc:\n",
    "        print('Learning rate decay : %.9f' % (learning_rate * weight))\n",
    "        return learning_rate * weight\n",
    "    else:\n",
    "        return learning_rate   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning started. It takes sometime.\n",
      "Epoch: 0001 cost = 0.865521912 train accuracy =  0.69588 validation accuracy =  0.59856\n",
      "Epoch: 0002 cost = 0.492787328 train accuracy =  0.81826 validation accuracy =  0.82432\n",
      "Epoch: 0003 cost = 0.448738484 train accuracy =  0.83531 validation accuracy =  0.83163\n",
      "Learning rate decay : 0.050000000\n",
      "Epoch: 0004 cost = 0.416369579 train accuracy =  0.84467 validation accuracy =  0.80489\n",
      "Learning rate decay : 0.025000000\n",
      "Epoch: 0005 cost = 0.390877555 train accuracy =  0.85383 validation accuracy =  0.71144\n",
      "Epoch: 0006 cost = 0.375255090 train accuracy =  0.86224 validation accuracy =  0.80399\n",
      "Epoch: 0007 cost = 0.359008015 train accuracy =  0.86934 validation accuracy =  0.85296\n",
      "Epoch: 0008 cost = 0.346009486 train accuracy =  0.87368 validation accuracy =  0.85357\n",
      "Learning rate decay : 0.012500000\n",
      "Epoch: 0009 cost = 0.330378491 train accuracy =  0.87946 validation accuracy =  0.84265\n",
      "Epoch: 0010 cost = 0.320127202 train accuracy =  0.88356 validation accuracy =  0.86629\n",
      "Learning rate decay : 0.006250000\n",
      "Epoch: 0011 cost = 0.309501002 train accuracy =  0.88722 validation accuracy =  0.85116\n",
      "Epoch: 0012 cost = 0.300271442 train accuracy =  0.88998 validation accuracy =  0.87169\n",
      "Learning rate decay : 0.003125000\n",
      "Epoch: 0013 cost = 0.297750630 train accuracy =  0.89121 validation accuracy =  0.86168\n",
      "Learning rate decay : 0.001562500\n",
      "Epoch: 0014 cost = 0.291388849 train accuracy =  0.89315 validation accuracy =  0.84115\n",
      "Learning rate decay : 0.000781250\n",
      "Epoch: 0015 cost = 0.288488879 train accuracy =  0.89375 validation accuracy =  0.80779\n",
      "Epoch: 0016 cost = 0.276170208 train accuracy =  0.89813 validation accuracy =  0.88702\n",
      "Learning rate decay : 0.000390625\n",
      "Epoch: 0017 cost = 0.275475040 train accuracy =  0.89929 validation accuracy =  0.84014\n",
      "Epoch: 0018 cost = 0.270481822 train accuracy =  0.90175 validation accuracy =  0.89473\n",
      "Learning rate decay : 0.000195313\n",
      "Epoch: 0019 cost = 0.266671466 train accuracy =  0.90287 validation accuracy =  0.88251\n",
      "Learning rate decay : 0.000097656\n",
      "Epoch: 0020 cost = 0.262805560 train accuracy =  0.90375 validation accuracy =  0.86298\n",
      "Learning rate decay : 0.000048828\n",
      "Epoch: 0021 cost = 0.260739636 train accuracy =  0.90461 validation accuracy =  0.64503\n",
      "Epoch: 0022 cost = 0.250745939 train accuracy =  0.90867 validation accuracy =  0.88992\n",
      "Learning rate decay : 0.000024414\n",
      "Epoch: 0023 cost = 0.244297429 train accuracy =  0.91009 validation accuracy =  0.88161\n",
      "Epoch: 0024 cost = 0.250326088 train accuracy =  0.90881 validation accuracy =  0.89433\n",
      "Learning rate decay : 0.000012207\n",
      "Epoch: 0025 cost = 0.240656901 train accuracy =  0.91159 validation accuracy =  0.86689\n",
      "Learning rate decay : 0.000006104\n",
      "Epoch: 0026 cost = 0.245690002 train accuracy =  0.91201 validation accuracy =  0.73758\n",
      "Epoch: 0027 cost = 0.236406019 train accuracy =  0.91385 validation accuracy =  0.89413\n",
      "Learning rate decay : 0.000003052\n",
      "Epoch: 0028 cost = 0.237524647 train accuracy =  0.91319 validation accuracy =  0.88301\n",
      "Learning rate decay : 0.000001526\n",
      "Epoch: 0029 cost = 0.228446916 train accuracy =  0.91753 validation accuracy =  0.88301\n",
      "Learning rate decay : 0.000000763\n",
      "Epoch: 0030 cost = 0.229186711 train accuracy =  0.91565 validation accuracy =  0.87620\n",
      "Learning rate decay : 0.000000381\n",
      "Epoch: 0031 cost = 0.221296554 train accuracy =  0.91847 validation accuracy =  0.84706\n",
      "Epoch: 0032 cost = 0.222149492 train accuracy =  0.91945 validation accuracy =  0.89673\n",
      "Learning rate decay : 0.000000191\n",
      "Epoch: 0033 cost = 0.219353540 train accuracy =  0.92063 validation accuracy =  0.89383\n",
      "Epoch: 0034 cost = 0.216477604 train accuracy =  0.92183 validation accuracy =  0.90224\n",
      "Learning rate decay : 0.000000095\n",
      "Epoch: 0035 cost = 0.213524371 train accuracy =  0.92153 validation accuracy =  0.87760\n",
      "Epoch: 0036 cost = 0.211978805 train accuracy =  0.92324 validation accuracy =  0.89904\n",
      "Epoch: 0037 cost = 0.212284337 train accuracy =  0.92414 validation accuracy =  0.90425\n",
      "Learning rate decay : 0.000000048\n",
      "Epoch: 0038 cost = 0.205577587 train accuracy =  0.92542 validation accuracy =  0.90274\n",
      "Learning rate decay : 0.000000024\n",
      "Epoch: 0039 cost = 0.202556728 train accuracy =  0.92676 validation accuracy =  0.89493\n",
      "Epoch: 0040 cost = 0.202111210 train accuracy =  0.92668 validation accuracy =  0.89824\n",
      "Learning rate decay : 0.000000012\n",
      "Epoch: 0041 cost = 0.202728558 train accuracy =  0.92654 validation accuracy =  0.88692\n",
      "Epoch: 0042 cost = 0.199905604 train accuracy =  0.92854 validation accuracy =  0.89804\n",
      "Epoch: 0043 cost = 0.195813994 train accuracy =  0.92902 validation accuracy =  0.89904\n",
      "Epoch: 0044 cost = 0.194167474 train accuracy =  0.92958 validation accuracy =  0.90815\n",
      "Learning rate decay : 0.000000006\n",
      "Epoch: 0045 cost = 0.189555218 train accuracy =  0.93170 validation accuracy =  0.89373\n",
      "Epoch: 0046 cost = 0.198546669 train accuracy =  0.92832 validation accuracy =  0.89704\n",
      "Learning rate decay : 0.000000003\n",
      "Epoch: 0047 cost = 0.194265489 train accuracy =  0.93004 validation accuracy =  0.77214\n",
      "Epoch: 0048 cost = 0.181737622 train accuracy =  0.93402 validation accuracy =  0.90485\n",
      "Learning rate decay : 0.000000001\n",
      "Epoch: 0049 cost = 0.184054204 train accuracy =  0.93362 validation accuracy =  0.88642\n",
      "Learning rate decay : 0.000000001\n",
      "Epoch: 0050 cost = 0.181550390 train accuracy =  0.93450 validation accuracy =  0.85206\n",
      "Learning Finished!\n"
     ]
    }
   ],
   "source": [
    "coord = tf.train.Coordinator()\n",
    "threads = tf.train.start_queue_runners(coord=coord, sess=sess)\n",
    "\n",
    "# train my model\n",
    "print('Learning started. It takes sometime.')\n",
    "pre_avg_val_acc = 0\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0.\n",
    "    avg_train_acc = 0.\n",
    "    avg_val_acc = 0.\n",
    "    total_batch = int(n_train / batch_size)\n",
    "    total_batch_val = int(n_val / batch_size)    \n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = sess.run([image_batch, label_batch])\n",
    "        batch_xs = batch_xs/255.\n",
    "        feed_dict = {X: batch_xs, Y: batch_ys, is_train: True}\n",
    "        #feed_dict = {X: batch_xs, Y: batch_ys, keep_prob: 0.7}\n",
    "        acc, c, _ = sess.run([accuracy, loss, optimizer], feed_dict=feed_dict)\n",
    "        avg_cost += c / total_batch\n",
    "        avg_train_acc += acc / total_batch\n",
    "        \n",
    "    for i in range(total_batch_val):\n",
    "        batch_xs, batch_ys = sess.run([image_val, label_val])\n",
    "        batch_xs = batch_xs/255.\n",
    "        feed_dict = {X: batch_xs, Y: batch_ys, is_train: False}\n",
    "        acc = sess.run(accuracy, feed_dict=feed_dict)\n",
    "        avg_val_acc += acc / total_batch_val\n",
    "   \n",
    "    # Learning rate decay when Validation accuracy decrease\n",
    "    learning_rate = learning_rate_decay(learning_rate, 0.5, pre_val_acc = pre_avg_val_acc, now_val_acc = avg_val_acc)\n",
    "    pre_avg_val_acc = avg_val_acc\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost), 'train accuracy = ', \n",
    "         '{:.5f}'.format(avg_train_acc), 'validation accuracy = ', '{:.5f}'.format(avg_val_acc))\n",
    "\n",
    "\n",
    "print('Learning Finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ubuntu/FC_Tensorflow_7th/jinsolkim/../checkpoints/jinsolkim.ckpt'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saver.save(sess, os.path.join(cwd, '..', 'checkpoints', save_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coord.request_stop()\n",
    "coord.join(threads) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
