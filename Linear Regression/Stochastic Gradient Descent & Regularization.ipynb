{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Gradient Descent & Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기본적인 Gradient Descent 식을 보면 다음과 같습니다.\n",
    "\n",
    "$\\theta _{j}:=\\theta_{j} - \\alpha\\frac{\\partial}{\\partial\\theta_{j}}J(\\theta_{0},\\theta_{1})$ <br><br>\n",
    "$\\frac{\\partial J}{\\partial w_{0}} = \\frac{1}{m} \\Sigma _{i=1}^{m}(w_{1}x^{i} + w_{0} - y^{(i)})$ <br><br>\n",
    "$\\frac{\\partial J}{\\partial w_{1}} = \\frac{1}{m} \\Sigma _{i=1}^{m}(w_{1}x^{i} + w_{0} - y^{(i)})x^{(i)}$\n",
    "\n",
    "위 식에서 사용할 때 수식 $\\Sigma _{i=1}^{m}$에서 알 수 있듯이 한 번에 모든 데이터를 이용하여 Gradient Descent를 수행하게 됩니다. 이렇게 한 번의 업데이트에 모든 데이터를 이용하는 것을 **Full-batch Gradient Descent** 라고 합니다. 한 번에 한 개의 데이터를 이용하여 gradient descent를 통한update 하는 것 보다 전체 데이터를 이용하여 update를 하는 것이 효과적입니다. \n",
    "\n",
    "용어를 정리하면, <br>\n",
    "- Gradient Descent : 1개의 데이터를 기준으로 미분. 즉, Singl Gradient Descent\n",
    "- Full-batch Gradient Descent : **모든 데이터 셋**으로 학습, 일반적인 GD라고 생각하면 됨\n",
    "<br>\n",
    "### Full-batch Gradient Descent를 사용하는 경우 문제점 <br>\n",
    "- 메모리 문제가 발생. RAM에 데이터를 upload 한 후 처리를 하게 되는데, 대용량 데이터를 한번에 upload하면 메모리 초과 문제가 발생한다.\n",
    "- 계산 속도가 느려져 모델의 파라미터 업데이트가 느려짐\n",
    "- 모든 데이터를 사용하여 update를 하기 때문에 local minimum에 빠지게 되면 탈출하기 어려움\n",
    "\n",
    "![1](./nb_images/sgd_graph.jpg)\n",
    "\n",
    "local minimum에 빠졌을 때 전체 데이터를 계속 사용하면 계속 같은 데이터를 사용하기 때문에 local minimum에 계속 빠져있으나, 일부 데이터만 사용하면 update 값이 변경되어 local minimum에 빠져나올 수도 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) SGD (Stochastic Gradient Descent)\n",
    "- 원래 의미는 dataset에서 random 하게 training sample을 뽑은 후 학습할 때 사용\n",
    "- data를 넣기 전에 shuffle\n",
    "\n",
    "### Pseudo-code\n",
    "Procedure **SGD** <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;suffle(X) <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;for i in number of X do<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$\\theta_{j}:=\\theta_{j} - \\alpha(\\hat{y}^{(i)}-y^{(i)})x_{j}^{(i)}$ <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;end for<br>\n",
    "end Procedure\n",
    "\n",
    "- 데이터를 하나 하나 업데이트 하기 때문에 업데이트는 빠르고 빈번하게 할 수 있음.\n",
    "- Full-batch GD에 비하여 local minimum에서 잘 빠져나올 수 있음\n",
    "- 대용량 데이터 적용 시 전체 데이터 수행하는 데 시간이 너무 오래 걸릴 수 있음\n",
    "\n",
    "## 2) Mini-batch Stochastic Gradient Descent\n",
    "\n",
    "- 한 번의 일정량의 데이터를 랜덤하게 뽑아서 학습\n",
    "- SGD와 Full-batch GD의 절충점\n",
    "- <span class=\"mark\">일반적으로 SGD라고 하면 Mini-batch SGD를 뜻함</span>\n",
    "\n",
    "### Epoch\n",
    "- Full batch 를 n번 실행하면 n epoch\n",
    "- 전체 데이터가 Training 데이터에 들어갈 때 카운팅\n",
    "\n",
    "### Batch size\n",
    "- 한 번에 학습되는 데이터의 갯수\n",
    "- 일반적으로 $2^N$ 크기의 Batch size를 사용 (CPU/GPU 원리 상 $2^N$ 단위로 동작함)\n",
    "\n",
    "ex) 총 5,120개의 Training data에 512 batch-size면 몇 번을 학습해야 1 epoch이 되는가? 10번\n",
    "\n",
    "### Pseudo-code\n",
    "Procedure **Mini-batch SGD** <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;suffle(X) <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;BS ← Batch Size <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;NB ← Number of Batches <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;NB ← len(X) // BS <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;for i in number of X do<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$\\theta_{j}:=\\theta_{j} - \\alpha\\Sigma_{k=i*BS}^{(i+1)*BS}(\\hat{y}^{(k)}-y^{(k)})x_{j}^{(k)}$ <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;end for<br>\n",
    "end Procedure\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-24T13:18:32.880566Z",
     "start_time": "2018-06-24T13:18:32.862613Z"
    }
   },
   "source": [
    "![1](./nb_images/iter_batch.png)\n",
    "\n",
    "위 그림과 같이 일반적으로 Iteration의 횟수가 많아질수록, Batch Size가 커질 수록 Cost가 줄어들게 됩니다. 하지만 메모리의 한계가 있으므로 적당한 선의 batch 사이즈를 결정해 주어야 합니다. \n",
    "\n",
    "![2](./nb_images/gd_sgd.png)\n",
    "위 그림은 Full-batch GD, Mini-batch GD, SGD의 cost 변화량을 비교한 것입니다. 이 때 SGD를 보면 매 번의 iteration 마다 변화량이 많은 것을 볼 수 있습니다. 끝 지점에 SGD의 cost 값을 일정 범위 수렴하기 위해서는 Learning Rate를 줄여줄 필요가 있습니다. 따라서 Learning Rate를 줄이는 Learning Rate Decay 방법에 대하여 알아보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Learning Rate Decay\n",
    "\n",
    "- 일정한 주기로 Learning Rate를 감소시키는 방법\n",
    "- 특정 Epoch 마다 Learning Rate를 감소시킴\n",
    "ex) 5 epoch 마다, alpha = alpha * 0.9\n",
    "- 감소 폭에 해당하는 Hyper-parameter를 지정해 주어야 한다.\n",
    "- 지수 감수 : $\\alpha = \\alpha_{0}e^{-kt}$ (Sci-kit learn에서 주로 default값으로 되어 있음)\n",
    "- $\\frac{1}{t}$ 감소 : $\\alpha = \\frac{\\alpha_{0}}{(1+kt)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) 종료 조건 설정\n",
    "\n",
    "- SGD 과정에서 특정 이하 값으로 cost function이 줄어 들지 않을 경우 GD를 멈추는 방법\n",
    "- 성능이 좋아지지 않는 경우 필요 없는 연산을 방지함\n",
    "- value > loss - previsous loss 인 경우 종료 (value 값은 hyper-parameter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Overfiting\n",
    "아래는 각각 **Underfit / Just right / Overfit**을 나타내는 학습 결과를 나타냅니다.\n",
    "![3](./nb_images/overfitting.png)\n",
    "\n",
    "**overfit**과 같이 학습 데이터를 과다하게 최적화 하는 경우 새로운 데이터 예측력이 떨어지게 됩니다.\n",
    "\n",
    "![4](./nb_images/bias_variance.png)\n",
    "![5](./nb_images/bias_variance2.png)\n",
    "\n",
    "또는 bias-variance tradeoff 관점에서 볼 수 도 있습니다.\n",
    "- **High bias** : weight가 특정 데이터에 편향되어 있음 (Underfit). 따라서 원래 모델에 떨어지게 되고 잘못됨 데이터만 계속 학습함(잘못된 weight만 업데이트)\n",
    "\n",
    "- **High variance** : weight가 너무 많은 데이터에 맞추어져 있음 (Overfit). 모든 데이터에 민감하게 학습하여 모든 weight가 업데이트됨\n",
    "\n",
    "![6](./nb_images/train_test_error.png)\n",
    "\n",
    "Train/Test set의 Error가 Epoch이 늘어날 수록 둘 다 줄어들어야 잘 학습하는 것이지만, **Train set의 Error는 줄어드는 반면 Test set의 Error가 늘어나게 된다면 overfitting**이 일어난다고 볼 수 있다.(범용성 성능이 떨어짐)\n",
    "\n",
    "### Overfitting을 극복하는 방법\n",
    "- 더 많은 데이터를 활용한다.\n",
    "- Feature의 갯수를 줄여 모델의 복잡도를 낮춥니다.\n",
    "- 적절한 Parameter를 선정합니다. (Trial-Error로 적당한 값을 찾아야 하나 쉽지 않음)\n",
    "- **Regularization**을 사용한다. 등등"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Regularization\n",
    "\n",
    "![7](./nb_images/regularization.png)\n",
    "\n",
    "위의 학습 model을 보면 overfitting이 되어 있음을 추정할 수 있습니다. Overfitting 발생 시 적용할 수 있는 간단한 테크닉 중 하나가 Regularization 입니다. <br>\n",
    "$y = \\theta^n x^n + \\theta^{n-1} x^{n-1} + ... + \\theta^2x^2 + \\theta x$ 와 같은 식이 있을 때, 모든 feature에 대한 weight값이 큰 경우 각각의 feature의 영향력이 모두 커져서 overfitting이 발생할 수 있습니다. 이 때 weight 값이 커지면 penalty를 부과하여 weight 값을 줄이는 방향으로 학습하는 것을 **regularization** 이라고 합니다. <br>\n",
    "$y = \\theta^n x^n + \\theta^{n-1} x^{n-1} + ... + \\theta^2x^2 + \\theta x$ 에서 <span class=\"mark\">각 $\\theta^i$의 값이 줄어들게 되면</span> low-variance, low-bias에 좀 더 가까워져서 알맞는 학습을 할 수 있게 됩니다.<br>\n",
    "예를 들면 다음과 같습니다. <br><br>\n",
    "$J(w_{0}, w_{1}) = \\frac{1}{2m}\\Sigma^{m}_{i=1}(w_{1}x_{1}^{(i)} + w_{0} - y^{(i)})^{2}$ 에서 $w_{1}$의 값이 크게 늘어나는 것을 방지하기 위하여 다음과 같이 식을 수정합니다. <br><br>\n",
    "\n",
    "$J(w_{0}, w_{1}) = \\frac{1}{2m}\\Sigma^{m}_{i=1}(w_{1}x_{1}^{(i)} + w_{0} - y^{(i)})^{2} + 1000w_{1}$ \n",
    "\n",
    "여기서 $1000w_{1}$으로 인하여 $w_{1}$의 값이 커지게 되면 $J(w_{0}, w_{1})$의 크기가 커지게 되므로 최종 목적인 min($J(w_{0}, w_{1})$)에 penalty가 주어지게 됩니다. 따라서 학습시 $J(w_{0}, w_{1})$을 줄이기 위하여 weight를 줄이는 방향으로 학습하게 됩니다. $w_{0}$ = bias 이므로 그래프 상 평행 이동과 관계가 있고 전체 model의 형태와는 무관하므로 일반적으로 regularization 시 고려하지는 않습니다.\n",
    "\n",
    "### L2 regularization\n",
    "- cost function에 L2(norm) penalty term을 추가<br><br>\n",
    "$J(\\theta) = \\frac{1}{2m}\\begin{bmatrix}\\Sigma^{m}_{i=1}(h_{\\theta}(x^{(i)}) - y^{(i)})^2 + \\lambda\\Sigma^{n}_{j=1}\\theta_{j}^{2}\\end{bmatrix}$ <br><br>\n",
    "\n",
    "- L2는 Euclidean Distance로 원점에서 벡터 좌표까지 거리를 나타냅니다. 하지만 square-root는 생략하여 제곱 형태만 식에 표현합니다.\n",
    "- L2 regularization 수식 <br><br>\n",
    "$J(\\theta) = \\frac{1}{2m}\\begin{bmatrix}\\Sigma^{m}_{i=1}(h_{\\theta}(x^{(i)}) - y^{(i)})^2 + \\lambda\\Sigma^{n}_{j=1}\\theta_{j}^{2}\\end{bmatrix}$ <br><br>\n",
    "$\\theta_{0}:= \\theta_{0} - \\alpha\\frac{1}{m}\\Sigma_{i=1}^{m}(h_{\\theta}(x^{(i)}) - y^{(i)})x_{0}^{(i)}$ <br><br>\n",
    "$\\theta_{j}:= \\theta_{j} - \\alpha\\begin{bmatrix}\\frac{1}{m}\\Sigma_{i=1}^{m}(h_{\\theta}(x^{(i)}) - y^{(i)})x_{j}^{(i)} + \\frac{\\lambda}{m}\\theta_{j}\\end{bmatrix} (j \\in 1, 2, ..., n)$ <br><br>\n",
    "\n",
    "- $\\lambda$는 hyper-parameter로 $\\lambda$ 값이 커지면 커질 수록 penalty 가 더 커져서 $\\theta$값 들이 작아지게 됩니다. <br>\n",
    "- $\\theta_{j}$로 term을 묶어보면 다음과 같습니다. <br><br>\n",
    "$\\theta_{j}:=\\theta_{j}(1 - \\alpha\\frac{\\lambda}{m}) - \\alpha\\frac{1}{m}\\Sigma_{i=1}^{m}(h_{\\theta}(x^{(i)}) - y^{(i)})x_{j}^{(i)}$ <br><br>\n",
    "- $(1 - \\alpha\\frac{\\lambda}{m}) \\leq 1$ 을 만족합니다. 일반적으로 $\\alpha < 1$ 값을 사용합니다. 그리고 $\\lambda$의 크기는 일반적으로 데이터의 크기 보다 작은 값을 사용하기 때문에 $\\frac{\\lambda}{m} < 1$ 을 만족합니다. 따라서 $(1 - \\alpha\\frac{\\lambda}{m}) \\leq 1$ 를 만족하므로 L2 regularization 적용 시 $\\theta$ 값은 줄어들게 됩니다.\n",
    "\n",
    "### L1 Regularization\n",
    "\n",
    "- L1은 Manhattan distance로 원점에서 벡터 좌표까지 거리를 나타냅니다.  <br><br>\n",
    "$\\lambda\\Sigma_{j=1}^{n}|\\theta_{j}|$ 의 수식을 가집니다. <br><br>\n",
    "- L2 Regularization을 기본적으로 사용하여 상세 내용은 생략합니다. 절대값이므로 미분 시 영역을 분할하여 미분한 결과를 적용해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
